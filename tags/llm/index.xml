<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Llm on (bit-mage)</title><link>https://rajp152k.github.io/tags/llm/</link><description>Recent content in Llm on (bit-mage)</description><generator>Hugo</generator><language>en-us</language><lastBuildDate>Sun, 16 Mar 2025 19:10:48 +0530</lastBuildDate><atom:link href="https://rajp152k.github.io/tags/llm/index.xml" rel="self" type="application/rss+xml"/><item><title>I wrote an Emacs Package</title><link>https://rajp152k.github.io/post/fabric-gpt.el/</link><pubDate>Sun, 16 Mar 2025 19:10:48 +0530</pubDate><guid>https://rajp152k.github.io/post/fabric-gpt.el/</guid><description>&lt;p>Fabric&lt;sup id="fnref:1">&lt;a href="#fn:1" class="footnote-ref" role="doc-noteref">1&lt;/a>&lt;/sup> is a collection of crowd-sourced prompts, exposed via a CLI tool. I used it for a while some time ago but never fully exploited it because I prefer Emacs.&lt;/p>
&lt;p>Eshell buffers are an option, but I am principled in my tool usage and prefer to delegate longer-running CLI tasks to a combination of Alacritty and Tmux.&lt;/p>
&lt;p>Maintaining my Emacs shell usage to ephemeral popups feels natural.&lt;/p>
&lt;p>Gptel&lt;sup id="fnref:2">&lt;a href="#fn:2" class="footnote-ref" role="doc-noteref">2&lt;/a>&lt;/sup> is a versatile LLM client that integrates smoothly into my workflow (buffer/text manipulation and management) without disrupting my thought flow.&lt;/p></description></item><item><title>Prompt Crafting Distilled</title><link>https://rajp152k.github.io/post/dense-guide-prompt-engineering/</link><pubDate>Thu, 21 Sep 2023 16:38:07 +0530</pubDate><guid>https://rajp152k.github.io/post/dense-guide-prompt-engineering/</guid><description>&lt;h1 id="the-premise">The Premise&lt;/h1>
&lt;p>I was initially reluctant on using generative AI for my writing
process.&lt;/p>
&lt;p>That being said, I was quite aware of the potential of large language
models (generically addressed as LLMs in here henceforth) -
especially true in the case of content creators and/or eccentrically
curious individuals.&lt;/p>
&lt;p>I, therefore, decided to clarify how I&amp;rsquo;ll be using generative AI for
my ideation process.&lt;/p>
&lt;h1 id="the-promise">The Promise&lt;/h1>
&lt;p>Before we get onto that, as promised by the title, distilling the
over-arching skills needed to extract good insights from a
conversation with an LLM (an el-el-em; please don&amp;rsquo;t read it as large, please..).&lt;/p></description></item></channel></rss>